好的，這是一份非常明確的產品演進方向！從一個純網頁 PoC（概念驗證）演進為一個更強大、更貼近使用者工作流程的桌面應用程式，這是一個很棒的升級。

我已經將您的想法整合，並捨棄了您決定暫緩的功能，撰寫了一份新的 PRD (版本 2.0)。這份文件將作為下一階段開發的藍圖。

-----

## **產品需求文件 (PRD): "EchoChat-Desktop" v1.2**

### **1. 文件資訊**

  * **專案名稱:** EchoChat-Desktop
  * **文件版本:** 1.2
  * **日期:** 2025年7月9日
  * **作者:** Gemini + User
  * **狀態:** **定稿**

### **2. 專案總覽與願景 (Project Overview & Vision)**

**總覽:**
EchoChat-Desktop 將從一個網頁應用程式進化為一個強大的桌面助理。透過整合 **Tauri** 框架，我們將突破瀏覽器的限制，實現對系統音訊的直接擷取。這讓 EchoChat 不再僅限於麥克風，更能成為一個能即時轉錄任何會議軟體、線上課程或系統聲音的智慧筆記與問答工具。

**願景:**
我們的願景是打造一個無縫融入使用者工作流程的「桌面端 AI 知識夥伴」。它能靜默地在背景聆聽、記錄、並理解使用者電腦上的所有音訊內容，並透過高度客製化的 AI 角色，提供最精準的互動與摘要，將使用者的工作與學習效率提升到新的層次。

### **3. 目標使用者 (Target Audience)**

此版本的目標使用者更為聚焦，主要針對需要在電腦上進行大量語音工作的「高效率工作者」：

  * **遠距工作者與團隊成員:** 需要記錄 Zoom, Google Meet, Teams 等線上會議內容，並快速生成會議摘要或針對特定內容提問。
  * **線上學習者:** 需要轉錄線上課程或教學影片，並能隨時與 AI 助教互動以鞏固知識。
  * **內容創作者:** Youtuber, Podcaster 在錄製或剪輯時，需要一個能即時產生逐字稿的工具。

### **4. 核心功能與範疇 (Core Features & Scope)**

#### **4.1. 桌面端整合與音訊來源擴增 (Tauri & Audio Source)**

1.  **Tauri 框架整合:**
      * 將現有的 Next.js 前端專案遷移至 Tauri 框架內運行，打包成跨平台（Windows, macOS, Linux）的桌面應用程式。
2.  **系統音訊擷取:**
      * **核心變更**: 放棄原先透過瀏覽器 `getUserMedia` 擷取麥克風的方式。
      * **新實作**: 利用 Tauri 的後端能力（Rust），開發一個系統音訊擷取模組。此模組負責抓取作業系統的音訊輸出（如喇叭正在播放的聲音）或特定應用程式的音訊流，並將其即時傳遞給前端，再由前端透過 WebSocket 轉發至 FastAPI 後端。

#### **4.2. AI 互動體驗升級**

1.  **動態 AI 角色設定 (Prompt Engineering):**
      * 在前端 UI 新增一個設定區塊或彈出式視窗。
      * 提供兩個輸入框：
          * **AI 角色 (System Prompt):** 讓使用者能自定義 AI 的系統提示。例如：「你是一位資深的專案經理，請用專業、精簡的口吻總結會議重點。」
          * **我的角色 (User Role):** 讓使用者能定義自己的身份，使 AI 的回應更具針對性。例如：「我是一位前端工程師。」
      * 這些設定將隨著每一次的聊天請求發送到後端。
2.  **前端 LLM Provider 選擇:**
      * 在前端 UI（例如聊天視窗附近）新增一個下拉式選單。
      * [cite\_start]選項包含目前後端支援的 "OpenAI" 與 "Gemini" [cite: 150, 151]。
      * 使用者的選擇將會跟隨聊天請求發送到後端，由後端動態切換對應的 LLM 服務。

#### **4.3. 部署與分發 (Deployment & Distribution)**

1.  **後端部署:**
      * 建立一個 `docker-compose.yml` 檔案。
      * 該檔案將用於打包 FastAPI 後端應用程式，方便在任何支援 Docker 的環境中一鍵啟動服務。
2.  **桌面應用程式分發:**
      * **目標**: 提供一個最簡單的方式讓使用者下載安裝。
      * **方案**:
          * 使用 `tauri build` 指令將應用程式打包成適用於各作業系統的原生安裝檔（Windows 為 `.msi`，macOS 為 `.dmg`）。
          * 設定 GitHub Actions 自動化流程：當有新的程式碼推送到主分支或建立新的 tag 時，自動觸發 Tauri 的打包程序。
          * 將打包好的安裝檔自動上傳到 GitHub Releases 頁面，使用者只需前往該頁面即可下載對應系統的版本。

### **5. 技術棧 (Technology Stack)**

  * **桌面應用框架:** **Tauri** (核心為 Rust)
  * **前端:**
      * 框架: **Next.js 14+** (運行於 Tauri WebView 中)
      * 語言: **TypeScript**
      * 樣式: **Tailwind CSS**
  * **後端:**
      * 框架: **FastAPI**
      * 語言: **Python 3.10+**
      * 部署: **Docker / Docker Compose**
  * **第三方服務:**
      * 語音轉文字 (STT): **Deepgram**
      * 大型語言模型 (LLM): **OpenAI / Google Gemini** (由前端動態選擇)

### **6. 系統架構與資料流 (System Architecture & Data Flow)**

```mermaid
graph TD
    subgraph Desktop App (Tauri + Next.js UI)
        A[使用者] --> B[UI Components];
        B -- "設定AI角色, 選擇LLM Provider" --> C[App State];
        
        subgraph Tauri Core (Rust)
            D[System Audio Capture] -- "Audio Bytes" --> E[Tauri-JS Bridge];
        end
        
        E -- "Audio Bytes" --> F[WebSocket Client];
        B -- "聊天提問 (含AI角色/Provider設定)" --> G[REST API Client];
        F -- "接收轉錄稿" --> B;
        G -- "接收AI回覆" --> B;
    end

    subgraph Server (FastAPI on Docker)
        H[WebSocket Endpoint\n/ws/stream] <--> F;
        H -- "Audio Bytes" --> I[STT Adapter\n(Deepgram)];
        I -- "Proxy Stream" --> J((Deepgram API));
        J -- "Transcript JSON" --> I;
        I -- "Formatted Transcript" --> H;

        K[REST API Endpoint\n/api/chat/completion] <--> G;
        K -- "(Context, Query, Prompts, Provider)" --> L[LLM Service Router];
        L -- "Selects & Calls" --> M[LLM Adapter\n(Gemini/OpenAI)];
        M -- "API Call" --> N((LLM Service API));
        N -- "Completion" --> M;
        M -- "Formatted Response" --> K;
    end
```

### **7. API 規格變更 (API Specification)**

為了支援前端的動態設定，後端的聊天相關 API 需要進行修改。

**`POST /api/chat/completion` & `POST /api/chat/stream`**

**Request Body Model (`ChatRequest`)** 需擴充欄位：

```python
# pydantic model in backend/src/echo_chat_backend/main.py

from typing import Optional

class ChatRequest(BaseModel):
    context: str
    query: str
    # --- 新增欄位 ---
    provider: Optional[str] = None       # e.g., "openai" or "gemini"
    system_prompt: Optional[str] = None  # AI 角色設定
    user_role: Optional[str] = None      # 使用者角色設定
```

後端邏輯需調整為：

1.  優先使用請求中傳入的 `provider`，若無則 fallback 到環境變數的設定。
2.  在呼叫 LLM Adapter 時，將 `system_prompt` 和 `user_role` 整合進傳送給語言模型的提示中。

### **8. 暫緩功能 (Out of Scope for v2.0)**

根據本次討論，以下功能將延後實作，以集中資源完成核心體驗的轉型：

  * **使用者帳號系統**
  * **非即時檔案上傳轉錄**